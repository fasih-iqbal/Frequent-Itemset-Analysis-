# Frequent-Itemset-Analysis
Frequent Itemset Analysis on Amazon  Metadata using Kafka


## Overview

This project focuses on conducting Frequent Itemset Analysis on Amazon Metadata utilizing the Apache Kafka streaming platform. The system is designed with a single producer and three consumers to efficiently process and analyze the data in real-time. The consumers implement the Apriori algorithm, the PCY algorithm, and compute average views and purchases for each product. The project employs MongoDB to store and manage the generated results from all consumers.

## Contributors
- Fasih Iqbal: Developer
- Jawad Ahmad: Developer
- Hassan Rizwan: Developer

## Files and Approach

1. **processing.py**: Selects essential columns from the dataset such as brand, category, and features. It preprocesses the data and saves the selected columns' information in a new file.

2. **producer.py**: Creates a producer to stream the preprocessed data in real-time.

3. **consumer1.py**: Implements the Apriori algorithm in the first consumer with insights and associations displayed in real-time. Utilizes a sliding window approach for efficient processing.

4. **consumer2.py**: Implements the PCY algorithm in the second consumer to find frequent itemsets, providing real-time insights and associations. Also uses a sliding window approach.

5. **consumer3.py**: **consumer3.py**: Calculates the average views and purchases for each product using a moving average method to analyze the streaming data. This approach enables continuous tracking and estimation of product performance, leading to informed decisions and potential alerts based on heuristic ratios.

6. **Database**: The results generated by all consumers are stored in MongoDB for further analysis and reference.

## Approach Overview

- **Sliding Window Approach**: The choice of the sliding window approach in consumers 1 and 2 enables real-time data processing within defined windows of the incoming stream. This approach allows for continuous analysis of the data without the need to store the entire data stream, making it suitable for streaming applications where memory efficiency and real-time insights are crucial.

## Usage

1. **Preprocessing and Data Streaming**: Use `processing.py` to prepare the necessary data and `producer.py` to stream the preprocessed data.
2. **Consumer Analysis**:
   - **Consumer 1 (Apriori Algorithm)**: Utilizes the Apriori algorithm for frequent itemset mining and insights. Run `consumer1.py`.
   - **Consumer 2 (PCY Algorithm)**: Implements the PCY algorithm for finding frequent itemsets. Execute `consumer2.py`.
   - **Consumer 3 (Average Views and Purchases)**: Calculates the average views and purchases for each product. Run `consumer3.py`.
3. **Database Storage**: Results from all consumers are saved in MongoDB for further analysis and storage.

## Future Improvements

- Enhance dynamic parameter tuning for the Apriori and PCY algorithms.
- Implement visualization tools for a more intuitive understanding of the frequent itemset analyses.

This README provides a comprehensive overview of the project, highlighting the methods employed, the rationale behind the selected approaches, and the contributions of the developers involved. Feel free to further enhance and refine the project based on feedback and future requirements.  
